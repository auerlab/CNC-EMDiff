#!/bin/sh -e

##########################################################################
#   Description:
#       Run hisat2 aligner on each RNA sample.
#
#   Dependencies:
#       Requires hisat2 index.  Run after *-hisat2-index.sbatch.
#
#       All necessary tools are assumed to be in PATH.  If this is not
#       the case, add whatever code is needed here to gain access.
#       (Adding such code to your .bashrc or other startup script is
#       generally a bad idea since it's too complicated to support
#       every program with one environment.)
#       
#   History:
#   Date        Name        Modification
#   2021-11-24  Jason Bacon Begin
##########################################################################

# Memory requirements can only be determined by trial and error.
# Run a sample job and monitor closely in "top" or run under a tool that
# reports maximum memory use.

# One job per sample
#lpjs jobs 18

# 3 processors for hisat2, 1 for samtools sort, all must be on the same node
#lpjs procs-per-job 4
#lpjs min-procs-per-node procs-per-job

# Chaperone log shows 5.2GB for 4 threads
# Be sure to adjust if # of threads is changed.  Total should be about
# the same, but divided by a different # of processors.
#lpjs pmem-per-proc 1500MB

#lpjs log-dir Logs/17-hisat2-align

##############################################################################
# Align with hisat2, which can handle splice junctions in RNA reads

# Set a default value for testing outside the LPJS environment
: ${LPJS_ARRAY_INDEX:=1}

# Document software versions used for publication
uname -a
hisat2 --version
pwd

# Adjust this and #lpjs jobs above to rerun limited samples
sample=$LPJS_ARRAY_INDEX

genome=$(Reference/genome-filename.sh)
cd Results/17-hisat2-align
gz1=$(echo ../04-trim/*sample${sample}-*-R1.fastq.gz)
gz2=$(echo ../04-trim/*sample${sample}-*-R2.fastq.gz)
gz_base=$(basename $gz1)
bam=${gz_base%-R*}.bam

# Set this to a partition with about 15GB of free space, preferably on the
# compute node's local disk.  Samtools sort uses this for many large
# temporary files, so using networked storage will
# hammer the cluster network and file servers.
tmpdir=/usr/tmp

# Show exact commands below in stderr output
set -x

hisat2 --threads $(($LPJS_PROCS_PER_JOB - 1)) -x ../16-hisat2-index/$genome \
    -1 $gz1 -2 $gz2 | samtools sort -T $tmpdir > $bam

# Not sure how helpful multithreading is here, but since we allocated
# the cores for hisat2 above, might as well use them.  It's not worth
# running a separate job for indexing.
samtools index -@ $LPJS_PROCS_PER_JOB -c $bam
