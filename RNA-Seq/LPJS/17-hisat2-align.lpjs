#!/bin/sh -e

##########################################################################
#   Description:
#       Run hisat2 aligner on each RNA sample.
#
#   Dependencies:
#       Requires hisat2 index.  Run after *-hisat2-index.sbatch.
#
#       All necessary tools are assumed to be in PATH.  If this is not
#       the case, add whatever code is needed here to gain access.
#       (Adding such code to your .bashrc or other startup script is
#       generally a bad idea since it's too complicated to support
#       every program with one environment.)
#       
#   History:
#   Date        Name        Modification
#   2021-11-24  Jason Bacon Begin
##########################################################################

# Memory requirements can only be determined by trial and error.
# Run a sample job and monitor closely in "top" or run under a tool that
# reports maximum memory use.

# One job per sample
#lpjs jobs 18

# 3 processors for hisat2, 1 for samtools sort, all must be on the same node
#lpjs processors-per-job 4
#lpjs threads-per-process processors-per-job
# lpjs peak-mem: 5239352 KiB / 4 procs / 1024 = 1279.138671875 MiB
#lpjs pmem-per-processor 1400MB
#lpjs log-dir Logs/17-hisat2-align
##############################################################################
# Update PATH on a chimeric cluster (multiple operating systems used for
# compute nodes)
#
# The PATH used by the package manager that installed LPJS (/usr/local for
# FreeBSD ports, usually /usr/pkg or /opt/pkg for pkgsrc), is automatically
# prepended to the default PATH.  This is overridden by "#lpjs path", so
# if we use it, we must add all directories ourselves.
#
# Add the default non-priveleged pkgsrc prefix used by auto-pkgsrc-setup.
#
# Caution: Different versions of rsync behave differently with respect
# to creating path components at the destination.  Newer rsync requires
# --mkpath while older ones included with macOS and RHEL do not support
# this flag. Set path to use pkgsrc rsync in ~/Pkgsrc/pkg or /opt/pkg.
#lpjs path ~/Pkgsrc/pkg/bin:/opt/pkg/bin:/usr/pkg/bin:/usr/local/bin:/usr/bin:/bin
#lpjs pull-command rsync --mkpath -r --copy-links %h:%s/Reference %h:%s/Results/16-hisat2-index %h:%s/Results/04-trim/\*sample%i-\*.zst .
#lpjs push-command rsync --mkpath -r %w/Results/17-hisat2-align %h:%s/Results

##############################################################################
# Align with hisat2, which can handle splice junctions in RNA reads

# Set a default value for testing outside the LPJS environment
: ${LPJS_ARRAY_INDEX:=1}

# Document software versions used for publication
uname -a
hisat2 --version
pwd

input_dir=Results/04-trim
output_dir=Results/17-hisat2-align
index_dir=Results/16-hisat2-index

marker=lpjs-$LPJS_SUBMIT_HOST-shared-fs-marker
if [ ! -e $marker ]; then
    # Using file transfer and temp directories on the compute node
    printf "$marker does not exist.  Organizing transferred files...\n"
    # Pull command left everything in .
    # Set up the same directory structure as on the submit node
    mkdir -p $input_dir $output_dir
    mv 16-hisat2-index Results/
    mv *.zst $input_dir
else
    printf "$marker found.  No need to transfer files.\n"
fi

# hisat2 can't yet handle zstd inputs.
# If your trimmed fastq files are in zstd
# format, this will convert to gzip format.
# Convert zstd to gz rather than raw to reduce NFS load from compute nodes
# --fast minimizes CPU usage in exchange for larger files
# It might be possible to use a named pipe, assuming hisat2 doesn't
# need to do seek operations on the input file.  However, generating
# gzip files doesn't take long.
zst1=$(echo $input_dir/*sample${LPJS_ARRAY_INDEX}-*-R1.fastq.zst)
zst2=$(echo $input_dir/*sample${LPJS_ARRAY_INDEX}-*-R2.fastq.zst)
gz1=${zst1%.zst}.gz
gz2=${zst2%.zst}.gz
# Run both at the same time, since we allocated 4 cores anyway
# These are CPU-bound, so disk will not usually be a bottleneck
# Don't try to reuse the .gz files, they may be incomplete from canceled jobs
printf "$zst1 -> $gz1, $zst2 -> $gz2 for hisat2...\n"
zstdcat $zst1 | gzip --fast --stdout > $gz1 &
zstdcat $zst2 | gzip --fast --stdout > $gz2
wait

# Adjust this and #lpjs jobs above to rerun limited samples
sample=$LPJS_ARRAY_INDEX

genome=$(Reference/genome-filename.sh)
cd $output_dir
gz_base=$(basename $gz1)
bam=${gz_base%-R*}.bam

# Set this to a partition with about 15GB of free space, preferably on the
# compute node's local disk.  Samtools sort uses this for many large
# temporary files, so using networked storage will
# hammer the cluster network and file servers.
tmpdir=/tmp

# Show exact commands below in stderr output
set -x

hisat2 --threads $(($LPJS_PROCESSORS_PER_JOB - 1)) -x ../16-hisat2-index/$genome \
    -1 $gz1 -2 $gz2 | samtools sort -T $tmpdir > $bam
rm -f $gz1 $gz2

# Not sure how helpful multithreading is here, but since we allocated
# the cores for hisat2 above, might as well use them.  It's not worth
# running a separate job for indexing.
samtools index -@ $LPJS_PROCESSORS_PER_JOB -c $bam
