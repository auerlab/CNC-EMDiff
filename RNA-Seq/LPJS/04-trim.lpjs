#!/bin/sh -e

##########################################################################
#   Script description:
#       Trim adapters and low quality ends from Lumina reads
#       Based on work of Dr. Andrea Rau:
#       https://github.com/andreamrau/OpticRegen_2019
#
#   Dependencies:
#       Requires directory structure.  Run after *-organize.sh.
#
#       All necessary tools are assumed to be in PATH.  If this is not
#       the case, add whatever code is needed here to gain access.
#       (Adding such code to your .bashrc or other startup script is
#       generally a bad idea since it's too complicated to support
#       every program with one environment.)
#
#   History:
#   Date        Name        Modification
#   2019-09-11  Jason Bacon Begin
##########################################################################

##########################################################################
# Cutadapt:
# Each job in the array will run a cutadapt (python) process and a
# compression process for part of the time.  If you don't want to
# oversubscribe compute nodes even for a little while, add --cpus-per-task=2
# There may be 2 pigz processes per job, but --cpus-per-task=3 doesn't help

##########################################################################
# Fastq-trim:
# Limit concurrent jobs to 9 to avoid becoming I/O-bound.
# Fastq-trim is so fast it ends up using only about 40% CPU while waiting
# for NFS on albacore (only gigabit Ethernet).  Clusters with higher
# speed networks and file servers can handle more jobs.
# We'll finish the job array just as fast running only 9 at a time and
# getting 80% CPU utilization.
# 2 xzcat, 2 gzip, and 1 fastq-trim, but xzcat and gzip use less than
# half a core each
 
# Set job array to number of samples.
#lpjs jobs 18
#lpjs procs-per-job 2
#lpjs min-procs-per-node procs-per-job
#lpjs pmem-per-proc 10MiB
# Uncomment and edit this if desored: #lpjs log-dir Logs/04-trim

# FreeBSD ports are installed under /usr/local
# pkgsrc packages in a non-priveleged tree installed by auto-pkgsrc-setup
# are installed under ~/Pkgsrc/pkg by default
# pkgsrc packages in a priveleged tree (installed by root) on Linux and netBSD
# are found under /usr/pkg by default
# pkgsrc packages in a priveleged tree (installed by root) on macOS
# are found under /opt/pkg by default (/usr is read-only on Macs)
# $HOME is not set on Darwin
# Prepend common pkgsrc bin directories if they exist
for prefix in /Users/$LPJS_USER_NAME/Pkgsrc/pkg \
	      /home/$LPJS_USER_NAME/Pkgsrc/pkg \
	      /usr/pkg \
	      /opt/pkg; do
    if [ -e $prefix ]; then
	PATH=$prefix/bin:$PATH
	export PATH
    fi
done

# Document software versions used for publication
uname -a
hostname
pwd
which fastq-trim
fastq-trim --version
printenv

# Won't work yet: ls command above needs access to files to generate pathname

marker=lpjs-$LPJS_SUBMIT_HOST-shared-fs-marker
if [ ! -e $marker ]; then
    printf "$marker does not exist.  Using rsync to transfer files.\n"
    printf "Fetching $LPJS_SUBMIT_HOST:$LPJS_SUBMIT_DIRECTORY/$infile1\n"
    
    # Recreate directory structure in temp working dir and pull
    # our input files into it
    input_dir='Results/01-organize/Raw-renamed'
    mkdir -p $input_dir
    input1="$input_dir/*sample${LPJS_ARRAY_INDEX}-*R1*"
    input2="$input_dir/*sample${LPJS_ARRAY_INDEX}-*R2*"
    set -x
    rsync --copy-links ${LPJS_SUBMIT_HOST}:$LPJS_SUBMIT_DIRECTORY/$input1 $input_dir
    rsync --copy-links ${LPJS_SUBMIT_HOST}:$LPJS_SUBMIT_DIRECTORY/$input2 $input_dir
    set +x
else
    printf "$marker found.  No need to transfer files.\n"
    input1=$(ls Results/01-organize/Raw-renamed/*sample${LPJS_ARRAY_INDEX}-*R1*)
    input2=$(ls Results/01-organize/Raw-renamed/*sample${LPJS_ARRAY_INDEX}-*R2*)
fi

base=$(basename $input1)
stem=${base%%-R*.fastq.xz}

##############################################################################
# Remove ~15 bases at 5' end due to bias and last base at 3' end
# 5' bias is probably due to non-random cleavage and not a
# quality issue, so -u +15 -U +15 is probably not necessary
# -u +15 -U +15 \

# https://www.rootusers.com/gzip-vs-bzip2-vs-xz-performance-comparison/
# xz offers the best compression by far, but is slow at mid (-5) to high (-9)
# compression levels.  At -1, xz is faster than bzip2 while providing
# comparable compression.  If you want even faster compression and are
# willing to sacrifice compression ratio, use .gz or no compression for
# outputs instead.  A ZFS filesystem with lz4 compression should provide
# enough compression for intermediate files without gzip, bzip2, or xz.
# However, this may cause a network bottleneck as all processes write
# uncompressed FASTQ over NFS.  Using at least gzip -1 will transfer some
# of the load to the compute node CPUs and reduce NFS traffic considerably.
#
# suffix=.xz
suffix=.zst
output1=Results/04-trim/${stem}-R1.fastq$suffix
output2=Results/04-trim/${stem}-R2.fastq$suffix

# Maximize compression throughput so gzip is not a bottleneck.  Can determine
# performance from fastq-trim CPU % in job-top.
# Don't use -1 if job is I/O bound.  Use the idle CPU to get better compression
# and reduce I/O.  The goal is to maximum CPU utilization of the fastq-trim
# process and the gzip processes, as shown by job-top.
# -4 seems to work best on albacore with its
# gigabit network.  Lower values are probably better with a high-speed network.
# Use the highest value that does not result in a lower CPU utilization
# for fastq-trim.
export GZIP=-4

if pwd | fgrep -q RNA-Seq; then
    adapter=AGATCGGAAGAG
else
    adapter=CTGTCTCTTATACACATCT
fi

# fastq-trim is 2.5x faster with 1 core than cutadapt with 2 cores
# Our reads use the default Illumina universal adapter,
# but we'll state it explicitly anyway
set -x
time fastq-trim --3p-adapter1 $adapter --3p-adapter2 $adapter \
    --min-qual 24 --polya-min-length 4 $input1 $output1 $input2 $output2
